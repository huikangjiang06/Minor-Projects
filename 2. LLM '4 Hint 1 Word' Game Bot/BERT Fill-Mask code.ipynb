{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "### hint_description is a dictionary that links every hint's ID to its corresponding description\n",
    "### there are a total of 118 hints \n",
    "\n",
    "TRAIN_TEXT = \"/bohr/train-7ul9/v2\"\n",
    "hint_description = Dataset.load_from_disk(TRAIN_TEXT + \"/dataset/hint_descriptions\")\n",
    "hint_description = {\n",
    "    x['ID']: {'description': x['Description'], 'icons': x['image']}\n",
    "    for x in hint_description\n",
    "}\n",
    "\n",
    "### 20 samples of hints and label, for validation\n",
    "\n",
    "validation_data = Dataset.load_from_disk(TRAIN_TEXT + \"/dataset/takehome_validation\")\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "model_dir = '/personal/bert-large-uncased/'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Best Prompt using Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "st_model = SentenceTransformer('/all-MiniLM-L6-v2')\n",
    "\n",
    "'''\n",
    "train_examples = []\n",
    "for val in validation_data:\n",
    "  train_examples.append(InputExample(texts=[give_best_prompt(val['hints']), {val['label']}], label=1))\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(st_model)\n",
    "\n",
    "st_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=20,\n",
    "    warmup_steps=5,\n",
    "    output_path='./model',\n",
    "    optimizer_params={'lr': 1e-5},\n",
    "    weight_decay=0.01,\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"/personal/\")\n",
    "\n",
    "def tuple_to_prompt(tuple):\n",
    "    sentence = \"A \"\n",
    "    for i, word in enumerate(tuple):\n",
    "        sentence += word\n",
    "        if i == 0:\n",
    "            sentence += \" related to \"\n",
    "        elif i < len(tuple) - 1:\n",
    "            sentence += \", and \"\n",
    "        else:\n",
    "            sentence += \".\"\n",
    "    return sentence\n",
    "\n",
    "def all_possible_prompts(hints: list[int]):\n",
    "    split_strings_list = []\n",
    "    prompt_list = []\n",
    "    for i, hint in enumerate(hints):\n",
    "        split_strings = hint_description[hint]['description'].split('\\n')\n",
    "        temp = []\n",
    "        for word in split_strings:\n",
    "            temp += word.split(\" - \")\n",
    "        split_strings = temp\n",
    "        split_strings_list.append(split_strings)\n",
    "    cartesian = itertools.product(*split_strings_list)\n",
    "    cartesian_list = []\n",
    "    for point in cartesian:\n",
    "        cartesian_list.append(point)\n",
    "        prompt_list.append(tuple_to_prompt(point))\n",
    "    return prompt_list, cartesian_list\n",
    "\n",
    "def find_closest_outlier(embeddings, eps=0.5, min_samples=5):\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(embeddings)\n",
    "    labels = clustering.labels_\n",
    "    outliers = embeddings[labels == -1]\n",
    "    inliers = embeddings[labels != -1]\n",
    "    if len(inliers) == 0:\n",
    "        return np.where(labels == -1)[0][0]\n",
    "    distances = pairwise_distances(inliers, outliers)\n",
    "    closest_outlier_indices = distances.argmin(axis=1)\n",
    "    closest_inlier_index = distances.min(axis=1).argmin()\n",
    "    return np.where(labels == -1)[0][closest_outlier_indices[closest_inlier_index]]\n",
    "    \n",
    "def find_middle_sentence(embeddings):\n",
    "    clustering = DBSCAN(eps=0.5, min_samples=5).fit(embeddings)\n",
    "    labels = clustering.labels_\n",
    "    unique_labels = set(labels)\n",
    "    unique_labels.discard(-1)\n",
    "    if not unique_labels:\n",
    "        return find_closest_outlier(embeddings)\n",
    "    main_cluster_label = max(unique_labels, key=lambda label: np.sum(labels == label))\n",
    "    main_cluster_indices = np.where(labels == main_cluster_label)[0]\n",
    "    main_cluster_embeddings = embeddings[main_cluster_indices]\n",
    "    cluster_center = np.mean(main_cluster_embeddings, axis=0)\n",
    "    closest_idx, _ = pairwise_distances_argmin_min(\n",
    "        cluster_center.reshape(1, -1), \n",
    "        main_cluster_embeddings\n",
    "    )\n",
    "    return main_cluster_indices[closest_idx[0]]\n",
    "\n",
    "def adj_adjust(hints:tuple):\n",
    "    sentence = \"A [MASK] is a \"\n",
    "    noun_list = []\n",
    "    adj_list = []\n",
    "    for i, hint in enumerate(hints):\n",
    "        word = hint\n",
    "        if i == 0:\n",
    "            sentence += word\n",
    "        else:\n",
    "            tags = nltk.pos_tag([\"A\",word.lower(),\"cat\"]) \n",
    "            if tags[1][1] in [\"JJ\",\"JJR\",\"JJS\"]:\n",
    "                adj_list.append(word)\n",
    "                sentence = sentence.replace(\"A [MASK] is a \",f\"A [MASK] is a {word} \")\n",
    "            else:\n",
    "                noun_list.append(word)\n",
    "    if len(adj_list)>=3:\n",
    "        return \"Too Many Adj\"\n",
    "    if len(noun_list)>0:\n",
    "        sentence += \" connected to \"\n",
    "    for i in range(len(noun_list)):\n",
    "        word = noun_list[i]\n",
    "        sentence += word\n",
    "        if i < len(noun_list)-1:\n",
    "            sentence += \", and \"\n",
    "        else:\n",
    "            sentence +=\".\"\n",
    "    sentence = sentence.replace('\\n', ', ')\n",
    "    return sentence\n",
    "\n",
    "def give_best_prompt(hints: list[int]):\n",
    "    prompts_list, cartesian_list = all_possible_prompts(hints)\n",
    "    embeddings = st_model.encode(prompts_list)\n",
    "    index = find_middle_sentence(embeddings)\n",
    "    best_cartesian = cartesian_list[index]\n",
    "    best_prompt = adj_adjust(best_cartesian)\n",
    "    if best_prompt == best_prompt:\n",
    "        best_prompt = prompts_list[index]\n",
    "        best_prompt = best_prompt.replace(\"A \", \"A [MASK] is a \")\n",
    "    return best_prompt\n",
    "    \n",
    "for i in range (20):\n",
    "    print(give_best_prompt(validation_data[i]['hints']))\n",
    "    print(validation_data[i]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BERT to fill [MASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'A [MASK] is a type of Clothing related to Head, and High, and Defence.'\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "mask_logits = outputs.logits[0, mask_token_index, :]\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(mask_logits, dim=-1)\n",
    "predicted_token_id = torch.argmax(probabilities).item()\n",
    "\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "print(f\"Input text: {text}\")\n",
    "print()\n",
    "#print(f\"Predicted token for [MASK]: {predicted_token}\")\n",
    "\n",
    "top_k = 10\n",
    "top_k_tokens_ids = torch.topk(mask_logits, top_k, dim=1).indices[0].tolist()\n",
    "top_k_tokens = [tokenizer.decode([token_id]) for token_id in top_k_tokens_ids]\n",
    "\n",
    "print(f\"Top {top_k} predictions:\")\n",
    "for i, token in enumerate(top_k_tokens):\n",
    "    print(f\"{i+1}. {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERTTopKMaskWord(input_sentence,candidate_words):\n",
    "    model.to('cpu')\n",
    "    inputs = tokenizer(input_sentence, return_tensors='pt')\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    mask_logits = logits[0, mask_token_index, :].squeeze()\n",
    "    \n",
    "    candidate_indices = [tokenizer.convert_tokens_to_ids(word) for word in candidate_words]\n",
    "    \n",
    "    candidate_logits = mask_logits[candidate_indices]\n",
    "    \n",
    "    _, topk_indices = torch.topk(candidate_logits,20)\n",
    "    \n",
    "    result_list = []\n",
    "    j = 0\n",
    "    for i in topk_indices:\n",
    "        if j == 10:\n",
    "            break\n",
    "        if candidate_words[i] not in result_list:\n",
    "            result_list.append(candidate_words[i])\n",
    "            j+=1\n",
    "        \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(guesses: list[str], gold: str):\n",
    "    # Normalize to lowercase\n",
    "    guesses = [g.lower() for g in guesses[:10]]\n",
    "    gold = gold.lower()\n",
    "\n",
    "    result = {\n",
    "        \"hits@10\": 0.0,\n",
    "        \"ndcg@10\": 0.0,\n",
    "        \"total_score\": 0.0\n",
    "    }\n",
    "\n",
    "    if gold in guesses:\n",
    "        rank = guesses.index(gold)\n",
    "        result[\"hits@10\"] = 1.0\n",
    "        result[\"ndcg@10\"] = 1.0 / math.log2(rank + 2)  # rank + 2 because index is 0-based\n",
    "    else:\n",
    "        result[\"hits@10\"] = 0.0\n",
    "        result[\"ndcg@10\"] = 0.0\n",
    "\n",
    "    result[\"total_score\"] = 0.9 * result[\"hits@10\"] + 0.1 * result[\"ndcg@10\"]\n",
    "    return result\n",
    "\n",
    "#print(score(['cat', 'dog', 'tree', 'flower', 'rock', 'water', 'fried rice', 'airplane', 'cactus', 'tiger'], gold='cactus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores=0\n",
    "for example in validation_data:\n",
    "    result_list = BERTTopKMaskWord( hints_to_sentence_ori(example['hints']), example['options'] )\n",
    "    print(hints_to_sentence_ori(example['hints']),example['label'],example['label'] in result_list)\n",
    "    total_scores += score(result_list, example['label'])['total_score']\n",
    "print(f\"Average validation score: {total_scores / len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_txt_file(file_path):\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read().strip()\n",
    "    \n",
    "    blocks = content.split('\\n\\n')\n",
    "    \n",
    "    data = []\n",
    "    for block in blocks:\n",
    "        lines = block.strip().split('\\n')\n",
    "        if len(lines) < 5:\n",
    "            continue \n",
    "            \n",
    "        elif len(lines) == 5:\n",
    "            hint1 = lines[0].rstrip(';').strip()\n",
    "            hint2 = lines[1].rstrip(';').strip()\n",
    "            hint3 = lines[2].rstrip(';').strip()\n",
    "            \n",
    "            options = lines[3].strip()\n",
    "            options = options.strip('{}').replace(' ', '').split(',')\n",
    "            \n",
    "            label = lines[4].strip()\n",
    "            \n",
    "            data.append([hint1, hint2, hint3, options, label])\n",
    "            \n",
    "        elif len(lines) == 6:\n",
    "            \n",
    "            hint1 = lines[0].rstrip(';').strip()\n",
    "            hint2 = lines[1].rstrip(';').strip()\n",
    "            hint3 = lines[2].rstrip(';').strip()\n",
    "            \n",
    "            options = lines[4].strip()\n",
    "            options = options.strip('{}').replace(' ', '').split(',')\n",
    "            \n",
    "            label = lines[5].strip()\n",
    "            \n",
    "            data.append([hint1, hint2, hint3, options, label])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['hint1', 'hint2', 'hint3', 'options', 'label'])\n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = '/personal/2.txt'\n",
    "data = parse_txt_file(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_prompts_df(df, idx):\n",
    "    split_strings_list = []\n",
    "    prompt_list = []\n",
    "    for i in range (3):\n",
    "        hint = df.iloc[idx,i]\n",
    "        split_strings = hint.split(', ')\n",
    "        split_strings_list.append(split_strings)\n",
    "    cartesian = itertools.product(*split_strings_list)\n",
    "    for point in cartesian:\n",
    "         prompt_list.append(tuple_to_prompt(point))\n",
    "    return prompt_list\n",
    "    \n",
    "def give_best_prompt_df(df,idx):\n",
    "    prompts_list = all_possible_prompts_df(df,idx)    \n",
    "    embeddings = st_model.encode(prompts_list)\n",
    "    index = find_middle_sentence(embeddings)\n",
    "    best_prompt = prompts_list[index]\n",
    "    best_prompt = best_prompt.replace(\"A \", \"A [MASK] is a type of \")\n",
    "    return best_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hints_to_sentence_df(df,idx):\n",
    "    sentence = \"[MASK] is a \"\n",
    "    for i in range(3):\n",
    "        hint = df.iloc[idx,i]\n",
    "        split_strings = hint.split(', ')\n",
    "        if i == 0:\n",
    "            sentence += f\"{split_strings[0]}\"\n",
    "            sentence += \" connected to \"\n",
    "        elif i < 2:\n",
    "            sentence += f\"{split_strings[0]}\"\n",
    "            sentence += \", and \"\n",
    "        else:\n",
    "            sentence += f\"{split_strings[0]}\"\n",
    "            sentence += \".\"\n",
    "    sentence = sentence.replace('\\n', ', ')\n",
    "    return sentence\n",
    "\n",
    "def choice_to_doc(choice:str)->str: ### Label to prompt \n",
    "  return f\"Our target word: {choice}\"\n",
    "\n",
    "i=14\n",
    "print(hints_to_sentence_df(data,i))\n",
    "print(data.loc[i,'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRA(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=8, alpha=16):\n",
    "        super().__init__()\n",
    "        self.rank = rank  ### LoRA的秩（rank），控制低秩矩阵的大小\n",
    "        self.scaling = alpha ### 用来控制lora层的scaling参数\n",
    "        self.A = nn.Linear(in_features, rank, bias=False)  ### 低秩矩阵A\n",
    "        self.B = nn.Linear(rank, out_features, bias=False)  ### 低秩矩阵B\n",
    "        \n",
    "        self.A.weight.data.normal_(mean=0.0, std=0.02) ### 矩阵参数初始化\n",
    "        self.B.weight.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.B(self.A(x)) * self.scaling\n",
    "\n",
    "def apply_lora(model, rank=8):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear) and module.weight.shape[0] == module.weight.shape[1]:\n",
    "            lora = LoRA(module.weight.shape[0], module.weight.shape[1], rank=rank).to(model.device)\n",
    "            setattr(module, \"lora\", lora)\n",
    "            original_forward = module.forward\n",
    "\n",
    "            # 显式绑定\n",
    "            def forward_with_lora(x, layer1=original_forward, layer2=lora):\n",
    "                return layer1(x) + layer2(x)\n",
    "\n",
    "            module.forward = forward_with_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,data,tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sentence = hints_to_sentence_df(self.data,idx)\n",
    "        candidate = self.data.loc[idx,'options']\n",
    "        label = self.data.loc[idx,'label']\n",
    "        \n",
    "        sentence = tokenizer(sentence, return_tensors='pt',padding='max_length',max_length=50)\n",
    "        \n",
    "        padding_length = 60 - len(candidate)\n",
    "        candidate = candidate + [tokenizer.pad_token] * padding_length\n",
    "        candidate = np.array([tokenizer.convert_tokens_to_ids(word) for word in candidate])\n",
    "        \n",
    "        label = tokenizer.convert_tokens_to_ids(label) #tokenizer(label, return_tensors='pt',padding='max_length',max_length=8)[\"input_ids\"][0]\n",
    "\n",
    "        return sentence, candidate, label\n",
    "\n",
    "class MyDataset_DS(torch.utils.data.Dataset):\n",
    "    def __init__(self,data,tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sentence = hints_to_sentence_ori(self.data[idx]['hints'])\n",
    "        candidate = self.data[idx]['options']\n",
    "        label = self.data[idx]['label']\n",
    "        \n",
    "        sentence = tokenizer(sentence, return_tensors='pt',padding='max_length',max_length=50)\n",
    "        \n",
    "        padding_length = 60 - len(candidate)\n",
    "        candidate = candidate + [tokenizer.pad_token] * padding_length\n",
    "        candidate = np.array([tokenizer.convert_tokens_to_ids(word) for word in candidate])\n",
    "        \n",
    "        label = tokenizer.convert_tokens_to_ids(label) #tokenizer(label, return_tensors='pt',padding='max_length',max_length=8)[\"input_ids\"][0]\n",
    "\n",
    "        return sentence, candidate, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, epochs=3, learning_rate=5e-5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    log1=[]\n",
    "    log2=[]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        train_loss = 0\n",
    "        \n",
    "        for sentence, candidate, label in loader:\n",
    "            \n",
    "            sentence = sentence.to(device)\n",
    "            sentence = {k: v.squeeze(1).to(device) for k, v in sentence.items()}\n",
    "            outputs = model(**sentence)\n",
    "            logits = outputs.logits\n",
    "            label = label.to(device)\n",
    "            candidate = candidate.to(device)\n",
    "\n",
    "            mask_token_index = [torch.where(sentence['input_ids'][i] == tokenizer.mask_token_id)[0] for i in range(label.size(0))]\n",
    "            mask_logits = logits[torch.arange(label.size(0)), mask_token_index, :].squeeze()\n",
    "\n",
    "            candidate_logits = torch.gather(mask_logits, \n",
    "                                            dim=1, \n",
    "                                            index=candidate.to(dtype=torch.int64)\n",
    "                               )\n",
    "\n",
    "            probs = torch.softmax(candidate_logits, dim=-1)\n",
    "\n",
    "            label_probs = torch.zeros_like(probs)\n",
    "            for i in range (label.size(0)):\n",
    "                sample1 = candidate[i]\n",
    "                label1 = label[i]\n",
    "                indeces = torch.where(sample1==label1)\n",
    "                for idx in indeces:\n",
    "                    label_probs[i,idx]=1\n",
    "\n",
    "            loss = criterion(probs, label_probs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "        total_scores=0\n",
    "        for example in test_dataset:\n",
    "            result_list = BERTTopKMaskWord(hints_to_sentence_ori(example['hints']),example['options'])\n",
    "            total_scores += score(result_list, example['label'])['total_score']\n",
    "        print(f\"Train Loss: {train_loss:.8f},     \"+f\"Average validation score: {total_scores*2 / len(validation_data)}\")\n",
    "        log1.append(train_loss)\n",
    "        log2.append(total_scores/len(validation_data))\n",
    "    return log1, log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/personal/bert-large-uncased/'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "apply_lora(model,rank=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_layers(model, indent=0):\n",
    "    for name, module in model.named_children():\n",
    "        print(\"  \" * indent + f\"{name}: {module.__class__.__name__}\")\n",
    "        if len(list(module.parameters())) > 0:\n",
    "            param = next(module.parameters())\n",
    "            print(\"  \" * (indent + 1) + f\"requires_grad={param.requires_grad}\")\n",
    "        if len(list(module.named_children())) > 0:\n",
    "            print_model_layers(module, indent + 2)           \n",
    "#print_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(validation_data))\n",
    "train_indices = [i for i in range(len(validation_data)) if i % 2 == 0]\n",
    "test_indices = [i for i in range(len(validation_data)) if i % 2 != 0]\n",
    "train_dataset = validation_data.select(train_indices)\n",
    "test_dataset = validation_data.select(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydataset = MyDataset_DS(train_dataset,tokenizer)\n",
    "loader = DataLoader(mydataset,batch_size=5,shuffle=True)\n",
    "losslog, scorelog = train_model(model,loader,epochs=30,learning_rate=5e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
