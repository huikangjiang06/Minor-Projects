{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "name": "stderr",
      "text": "/opt/mamba/lib/python3.12/site-packages/transformers/utils/hub.py:125: FutureWarning: Using the environment variable `HUGGINGFACE_CO_RESOLVE_ENDPOINT` is deprecated and will be removed in Transformers v5. Use `HF_ENDPOINT` instead.\n  warnings.warn(\n"
     },
     "id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_729",
     "meta": {},
     "name": "stderr",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-07-21T13:49:10.037498Z",
      "msg_id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_729",
      "msg_type": "stream",
      "session": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "/opt/mamba/lib/python3.12/site-packages/transformers/utils/hub.py:125: FutureWarning: Using the environment variable `HUGGINGFACE_CO_RESOLVE_ENDPOINT` is deprecated and will be removed in Transformers v5. Use `HF_ENDPOINT` instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at /personal/bert-large-uncased/ were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "execution_count": 72,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_731",
     "meta": {
      "dependencies_met": true,
      "engine": "22cb1541-d728-400f-b81b-aeac9db8390e",
      "started": "2025-07-21T13:49:09.029202Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-21T13:49:22.961102Z",
      "msg_id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_731",
      "msg_type": "execute_reply",
      "session": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "### hint_description is a dictionary that links every hint's ID to its corresponding description\n",
    "### there are a total of 118 hints \n",
    "\n",
    "TRAIN_TEXT = \"/bohr/train-7ul9/v2\"\n",
    "hint_description = Dataset.load_from_disk(TRAIN_TEXT + \"/dataset/hint_descriptions\")\n",
    "hint_description = {\n",
    "    x['ID']: {'description': x['Description'], 'icons': x['image']}\n",
    "    for x in hint_description\n",
    "}\n",
    "\n",
    "### 20 samples of hints and label, for validation\n",
    "\n",
    "validation_data = Dataset.load_from_disk(TRAIN_TEXT + \"/dataset/takehome_validation\")\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "model_dir = '/personal/bert-large-uncased/'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Best Prompt using Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_examples = []\\nfor val in validation_data:\\n  train_examples.append(InputExample(texts=[give_best_prompt(val['hints']), {val['label']}], label=1))\\n\\ntrain_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)\\n\\ntrain_loss = losses.CosineSimilarityLoss(st_model)\\n\\nst_model.fit(\\n    train_objectives=[(train_dataloader, train_loss)],\\n    epochs=20,\\n    warmup_steps=5,\\n    output_path='./model',\\n    optimizer_params={'lr': 1e-5},\\n    weight_decay=0.01,\\n    save_best_model=True,\\n    show_progress_bar=True\\n)\\n\""
      ]
     },
     "id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_735",
     "meta": {},
     "output_type": "execute_result",
     "parent_header": {
      "date": "2025-07-21T13:49:28.327282Z",
      "msg_id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_735",
      "msg_type": "execute_result",
      "session": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f",
      "username": "username",
      "version": "5.3"
     }
    },
    {
     "data": {
      "execution_count": 73,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_736",
     "meta": {
      "dependencies_met": true,
      "engine": "22cb1541-d728-400f-b81b-aeac9db8390e",
      "started": "2025-07-21T13:49:27.476871Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-21T13:49:28.329181Z",
      "msg_id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_736",
      "msg_type": "execute_reply",
      "session": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "st_model = SentenceTransformer('/all-MiniLM-L6-v2')\n",
    "\n",
    "'''\n",
    "train_examples = []\n",
    "for val in validation_data:\n",
    "  train_examples.append(InputExample(texts=[give_best_prompt(val['hints']), {val['label']}], label=1))\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(st_model)\n",
    "\n",
    "st_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=20,\n",
    "    warmup_steps=5,\n",
    "    output_path='./model',\n",
    "    optimizer_params={'lr': 1e-5},\n",
    "    weight_decay=0.01,\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "name": "stdout",
      "text": "A [MASK] is a Fauna related to Water, and Ground, and Grey, and Fast.\nseal\nA [MASK] is a Game related to Sphere, and Black, and Blue, and Green, and Yellow, and Orange, and Red, and Do, and Straight.\nbilliards\nA [MASK] is a Occupation related to Defence, and Burn.\nfirefighters\nA [MASK] is a Animal related to Seacraft, and Evening, and Do, and Hearing.\nbat\nA [MASK] is a Day related to Sight, and None, and Sun.\neclipse\nA [MASK] is a Food related to Flora, and Brown.\npotato\nA [MASK] is a Food related to Nature, and Brown, and Small.\npeanut\nA [MASK] is a Fauna related to Black, and White, and World, and Cold.\npenguin\nA [MASK] is a Clothing related to Arm.\ngloves\nA [MASK] is a Clothing related to Head, and High, and Defence.\nhelmet\nA [MASK] is a Fauna related to Water, and Ground, and Grey, and Fast.\nseal\nA [MASK] is a Game related to Sphere, and Black, and Blue, and Green, and Yellow, and Orange, and Red, and Do, and Straight.\nbilliards\nA [MASK] is a Occupation related to Defence, and Burn.\nfirefighters\n"
     },
     "id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_745",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-07-21T13:49:50.268788Z",
      "msg_id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_745",
      "msg_type": "stream",
      "session": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "A [MASK] is a Fauna related to Water, and Ground, and Grey, and Fast.\n",
      "seal\n",
      "A [MASK] is a Game related to Sphere, and Black, and Blue, and Green, and Yellow, and Orange, and Red, and Do, and Straight.\n",
      "billiards\n",
      "A [MASK] is a Occupation related to Defence, and Burn.\n",
      "firefighters\n",
      "A [MASK] is a Animal related to Seacraft, and Evening, and Do, and Hearing.\n",
      "bat\n",
      "A [MASK] is a Day related to Sight, and None, and Sun.\n",
      "eclipse\n",
      "A [MASK] is a Food related to Flora, and Brown.\n",
      "potato\n",
      "A [MASK] is a Food related to Nature, and Brown, and Small.\n",
      "peanut\n",
      "A [MASK] is a Fauna related to Black, and White, and World, and Cold.\n",
      "penguin\n",
      "A [MASK] is a Clothing related to Arm.\n",
      "gloves\n",
      "A [MASK] is a Clothing related to Head, and High, and Defence.\n",
      "helmet\n",
      "A [MASK] is a Fauna related to Water, and Ground, and Grey, and Fast.\n",
      "seal\n",
      "A [MASK] is a Game related to Sphere, and Black, and Blue, and Green, and Yellow, and Orange, and Red, and Do, and Straight.\n",
      "billiards\n",
      "A [MASK] is a Occupation related to Defence, and Burn.\n",
      "firefighters\n",
      "A [MASK] is a Animal related to Seacraft, and Evening, and Do, and Hearing.\n",
      "bat\n",
      "A [MASK] is a Day related to Sight, and None, and Sun.\n",
      "eclipse\n",
      "A [MASK] is a Food related to Flora, and Brown.\n",
      "potato\n",
      "A [MASK] is a Food related to Nature, and Brown, and Small.\n",
      "peanut\n",
      "A [MASK] is a Fauna related to Black, and White, and World, and Cold.\n",
      "penguin\n",
      "A [MASK] is a Clothing related to Arm.\n",
      "gloves\n",
      "A [MASK] is a Clothing related to Head, and High, and Defence.\n",
      "helmet\n"
     ]
    },
    {
     "data": {
      "execution_count": 75,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_747",
     "meta": {
      "dependencies_met": true,
      "engine": "22cb1541-d728-400f-b81b-aeac9db8390e",
      "started": "2025-07-21T13:49:50.047954Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-21T13:49:50.397176Z",
      "msg_id": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f_10968_747",
      "msg_type": "execute_reply",
      "session": "e2a3c93c-9e6ddc4b0a3b09aa9c48219f",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "nltk.data.path.append(\"/personal/\")\n",
    "\n",
    "def tuple_to_prompt(tuple):\n",
    "    sentence = \"A \"\n",
    "    for i, word in enumerate(tuple):\n",
    "        sentence += word\n",
    "        if i == 0:\n",
    "            sentence += \" related to \"\n",
    "        elif i < len(tuple) - 1:\n",
    "            sentence += \", and \"\n",
    "        else:\n",
    "            sentence += \".\"\n",
    "    return sentence\n",
    "\n",
    "def all_possible_prompts(hints: list[int]):\n",
    "    split_strings_list = []\n",
    "    prompt_list = []\n",
    "    for i, hint in enumerate(hints):\n",
    "        split_strings = hint_description[hint]['description'].split('\\n')\n",
    "        temp = []\n",
    "        for word in split_strings:\n",
    "            temp += word.split(\" - \")\n",
    "        split_strings = temp\n",
    "        split_strings_list.append(split_strings)\n",
    "    cartesian = itertools.product(*split_strings_list)\n",
    "    cartesian_list = []\n",
    "    for point in cartesian:\n",
    "        cartesian_list.append(point)\n",
    "        prompt_list.append(tuple_to_prompt(point))\n",
    "    return prompt_list, cartesian_list\n",
    "\n",
    "def find_closest_outlier(embeddings, eps=0.5, min_samples=5):\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(embeddings)\n",
    "    labels = clustering.labels_\n",
    "    outliers = embeddings[labels == -1]\n",
    "    inliers = embeddings[labels != -1]\n",
    "    if len(inliers) == 0:\n",
    "        return np.where(labels == -1)[0][0]\n",
    "    distances = pairwise_distances(inliers, outliers)\n",
    "    closest_outlier_indices = distances.argmin(axis=1)\n",
    "    closest_inlier_index = distances.min(axis=1).argmin()\n",
    "    return np.where(labels == -1)[0][closest_outlier_indices[closest_inlier_index]]\n",
    "    \n",
    "def find_middle_sentence(embeddings):\n",
    "    clustering = DBSCAN(eps=0.5, min_samples=5).fit(embeddings)\n",
    "    labels = clustering.labels_\n",
    "    unique_labels = set(labels)\n",
    "    unique_labels.discard(-1)\n",
    "    if not unique_labels:\n",
    "        return find_closest_outlier(embeddings)\n",
    "    main_cluster_label = max(unique_labels, key=lambda label: np.sum(labels == label))\n",
    "    main_cluster_indices = np.where(labels == main_cluster_label)[0]\n",
    "    main_cluster_embeddings = embeddings[main_cluster_indices]\n",
    "    cluster_center = np.mean(main_cluster_embeddings, axis=0)\n",
    "    closest_idx, _ = pairwise_distances_argmin_min(\n",
    "        cluster_center.reshape(1, -1), \n",
    "        main_cluster_embeddings\n",
    "    )\n",
    "    return main_cluster_indices[closest_idx[0]]\n",
    "\n",
    "def adj_adjust(hints:tuple):\n",
    "    sentence = \"A [MASK] is a \"\n",
    "    noun_list = []\n",
    "    adj_list = []\n",
    "    for i, hint in enumerate(hints):\n",
    "        word = hint\n",
    "        if i == 0:\n",
    "            sentence += word\n",
    "        else:\n",
    "            tags = nltk.pos_tag([\"A\",word.lower(),\"cat\"]) \n",
    "            if tags[1][1] in [\"JJ\",\"JJR\",\"JJS\"]:\n",
    "                adj_list.append(word)\n",
    "                sentence = sentence.replace(\"A [MASK] is a \",f\"A [MASK] is a {word} \")\n",
    "            else:\n",
    "                noun_list.append(word)\n",
    "    if len(adj_list)>=3:\n",
    "        return \"Too Many Adj\"\n",
    "    if len(noun_list)>0:\n",
    "        sentence += \" connected to \"\n",
    "    for i in range(len(noun_list)):\n",
    "        word = noun_list[i]\n",
    "        sentence += word\n",
    "        if i < len(noun_list)-1:\n",
    "            sentence += \", and \"\n",
    "        else:\n",
    "            sentence +=\".\"\n",
    "    sentence = sentence.replace('\\n', ', ')\n",
    "    return sentence\n",
    "\n",
    "def give_best_prompt(hints: list[int]):\n",
    "    prompts_list, cartesian_list = all_possible_prompts(hints)\n",
    "    embeddings = st_model.encode(prompts_list)\n",
    "    index = find_middle_sentence(embeddings)\n",
    "    best_cartesian = cartesian_list[index]\n",
    "    best_prompt = adj_adjust(best_cartesian)\n",
    "    if best_prompt == best_prompt:\n",
    "        best_prompt = prompts_list[index]\n",
    "        best_prompt = best_prompt.replace(\"A \", \"A [MASK] is a \")\n",
    "    return best_prompt\n",
    "    \n",
    "for i in range (20):\n",
    "    print(give_best_prompt(validation_data[i]['hints']))\n",
    "    print(validation_data[i]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BERT to fill [MASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "name": "stdout",
      "text": "Input text: A [MASK] is a type of Clothing related to Head, and High, and Defence.\n\nTop 10 predictions:\n1. helmet\n2. mask\n3. cape\n4. cap\n5. hood\n6. costume\n7. hat\n8. uniform\n9. vest\n10. dress\n"
     },
     "id": "4d9dfa97-3f62bbc0c876ac8b355c6bae_386_2769",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-07-16T15:48:14.149920Z",
      "msg_id": "4d9dfa97-3f62bbc0c876ac8b355c6bae_386_2769",
      "msg_type": "stream",
      "session": "4d9dfa97-3f62bbc0c876ac8b355c6bae",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "Input text: A [MASK] is a type of Clothing related to Head, and High, and Defence.\n",
      "\n",
      "Top 10 predictions:\n",
      "1. helmet\n",
      "2. mask\n",
      "3. cape\n",
      "4. cap\n",
      "5. hood\n",
      "6. costume\n",
      "7. hat\n",
      "8. uniform\n",
      "9. vest\n",
      "10. dress\n"
     ]
    },
    {
     "data": {
      "execution_count": 296,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "4d9dfa97-3f62bbc0c876ac8b355c6bae_386_2770",
     "meta": {
      "dependencies_met": true,
      "engine": "f103f043-a0bf-4c3c-a1a0-f20f39b6a8bf",
      "started": "2025-07-16T15:48:14.041088Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-16T15:48:14.150937Z",
      "msg_id": "4d9dfa97-3f62bbc0c876ac8b355c6bae_386_2770",
      "msg_type": "execute_reply",
      "session": "4d9dfa97-3f62bbc0c876ac8b355c6bae",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "text = 'A [MASK] is a type of Clothing related to Head, and High, and Defence.'\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "mask_logits = outputs.logits[0, mask_token_index, :]\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(mask_logits, dim=-1)\n",
    "predicted_token_id = torch.argmax(probabilities).item()\n",
    "\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "print(f\"Input text: {text}\")\n",
    "print()\n",
    "#print(f\"Predicted token for [MASK]: {predicted_token}\")\n",
    "\n",
    "top_k = 10\n",
    "top_k_tokens_ids = torch.topk(mask_logits, top_k, dim=1).indices[0].tolist()\n",
    "top_k_tokens = [tokenizer.decode([token_id]) for token_id in top_k_tokens_ids]\n",
    "\n",
    "print(f\"Top {top_k} predictions:\")\n",
    "for i, token in enumerate(top_k_tokens):\n",
    "    print(f\"{i+1}. {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "execution_count": 5,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_32",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T07:04:20.865972Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T07:04:20.869197Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_32",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "def BERTTopKMaskWord(input_sentence,candidate_words):\n",
    "    model.to('cpu')\n",
    "    inputs = tokenizer(input_sentence, return_tensors='pt')\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"][0] == tokenizer.mask_token_id)[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    mask_logits = logits[0, mask_token_index, :].squeeze()\n",
    "    \n",
    "    candidate_indices = [tokenizer.convert_tokens_to_ids(word) for word in candidate_words]\n",
    "    \n",
    "    candidate_logits = mask_logits[candidate_indices]\n",
    "    \n",
    "    _, topk_indices = torch.topk(candidate_logits,20)\n",
    "    \n",
    "    result_list = []\n",
    "    j = 0\n",
    "    for i in topk_indices:\n",
    "        if j == 10:\n",
    "            break\n",
    "        if candidate_words[i] not in result_list:\n",
    "            result_list.append(candidate_words[i])\n",
    "            j+=1\n",
    "        \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "execution_count": 6,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_36",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T07:04:23.436445Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T07:04:23.439200Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_36",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "def score(guesses: list[str], gold: str):\n",
    "    # Normalize to lowercase\n",
    "    guesses = [g.lower() for g in guesses[:10]]\n",
    "    gold = gold.lower()\n",
    "\n",
    "    result = {\n",
    "        \"hits@10\": 0.0,\n",
    "        \"ndcg@10\": 0.0,\n",
    "        \"total_score\": 0.0\n",
    "    }\n",
    "\n",
    "    if gold in guesses:\n",
    "        rank = guesses.index(gold)\n",
    "        result[\"hits@10\"] = 1.0\n",
    "        result[\"ndcg@10\"] = 1.0 / math.log2(rank + 2)  # rank + 2 because index is 0-based\n",
    "    else:\n",
    "        result[\"hits@10\"] = 0.0\n",
    "        result[\"ndcg@10\"] = 0.0\n",
    "\n",
    "    result[\"total_score\"] = 0.9 * result[\"hits@10\"] + 0.1 * result[\"ndcg@10\"]\n",
    "    return result\n",
    "\n",
    "#print(score(['cat', 'dog', 'tree', 'flower', 'rock', 'water', 'fried rice', 'airplane', 'cactus', 'tiger'], gold='cactus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "name": "stdout",
      "text": "A [MASK] is a Fauna connected to Water, and Earth, and Grey, and Fast. seal False\nA [MASK] is a Game connected to Sphere, and Black, and Blue, and Green, and Yellow, and Orange, and Red, and Use - Action, and Line - Straight. billiards False\nA [MASK] is a Work connected to Defence, and Fire. firefighters True\n"
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1362",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-07-17T09:02:13.635195Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1362",
      "msg_type": "stream",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "A [MASK] is a Fauna connected to Water, and Earth, and Grey, and Fast. seal False\n",
      "A [MASK] is a Game connected to Sphere, and Black, and Blue, and Green, and Yellow, and Orange, and Red, and Use - Action, and Line - Straight. billiards False\n",
      "A [MASK] is a Work connected to Defence, and Fire. firefighters True\n",
      "A [MASK] is a Fauna connected to Seacraft, and Night - Evening, and Use - Action, and Ear. bat True\n",
      "A [MASK] is a Date connected to Eye, and Zero, and Hot. eclipse True\n",
      "A [MASK] is a Food connected to Flora, and Brown. potato True\n",
      "A [MASK] is a Food connected to Flora, and Brown, and Small. peanut True\n",
      "A [MASK] is a Fauna connected to Black, and White, and Place - Country, and Cold. penguin True\n",
      "A [MASK] is a Clothing connected to Arm. gloves True\n",
      "A [MASK] is a Clothing connected to Head, and High, and Defence. helmet True\n",
      "A [MASK] is a Fauna connected to Water, and Earth, and Grey, and Fast. seal False\n",
      "A [MASK] is a Game connected to Sphere, and Black, and Blue, and Green, and Yellow, and Orange, and Red, and Use - Action, and Line - Straight. billiards False\n",
      "A [MASK] is a Work connected to Defence, and Fire. firefighters True\n",
      "A [MASK] is a Fauna connected to Seacraft, and Night - Evening, and Use - Action, and Ear. bat True\n",
      "A [MASK] is a Date connected to Eye, and Zero, and Hot. eclipse True\n",
      "A [MASK] is a Food connected to Flora, and Brown. potato True\n",
      "A [MASK] is a Food connected to Flora, and Brown, and Small. peanut False\n",
      "A [MASK] is a Fauna connected to Black, and White, and Place - Country, and Cold. penguin True\n",
      "A [MASK] is a Clothing connected to Arm. gloves False\n",
      "A [MASK] is a Clothing connected to Head, and High, and Defence. helmet True\n",
      "Average validation score: 0.6728507769896404\n"
     ]
    },
    {
     "data": {
      "execution_count": 162,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1369",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T09:02:13.321806Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T09:02:14.974365Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1369",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "total_scores=0\n",
    "for example in validation_data:\n",
    "    result_list = BERTTopKMaskWord( hints_to_sentence_ori(example['hints']), example['options'] )\n",
    "    print(hints_to_sentence_ori(example['hints']),example['label'],example['label'] in result_list)\n",
    "    total_scores += score(result_list, example['label'])['total_score']\n",
    "print(f\"Average validation score: {total_scores / len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hint1</th>\n",
       "      <th>hint2</th>\n",
       "      <th>hint3</th>\n",
       "      <th>options</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mountain, peak, climb</td>\n",
       "      <td>snow, cold, summit</td>\n",
       "      <td>adventure, gear, height</td>\n",
       "      <td>[mountain, volcano, hill, glacier, rock, climb...</td>\n",
       "      <td>volcano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plant, petal, bloom</td>\n",
       "      <td>sun, star, heat</td>\n",
       "      <td>field, grow, yellow</td>\n",
       "      <td>[sunflower, daisy, rose, plant, summer, garden...</td>\n",
       "      <td>sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ball, sport, round</td>\n",
       "      <td>leg, toe, kick</td>\n",
       "      <td>game, play, goal</td>\n",
       "      <td>[football, soccer, baseball, tennis, basketbal...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fly, insect, wing</td>\n",
       "      <td>fire, flame, hot</td>\n",
       "      <td>night, light, bug</td>\n",
       "      <td>[firefly, dragonfly, moth, beetle, glow, lante...</td>\n",
       "      <td>firefly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bow, arc, color</td>\n",
       "      <td>rain, water, wet</td>\n",
       "      <td>sky, storm, prism</td>\n",
       "      <td>[rainbow, weather, cloud, sun, spectrum, light...</td>\n",
       "      <td>rainbow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   hint1               hint2                    hint3  \\\n",
       "0  mountain, peak, climb  snow, cold, summit  adventure, gear, height   \n",
       "1    plant, petal, bloom     sun, star, heat      field, grow, yellow   \n",
       "2     ball, sport, round      leg, toe, kick         game, play, goal   \n",
       "3      fly, insect, wing    fire, flame, hot        night, light, bug   \n",
       "4        bow, arc, color    rain, water, wet        sky, storm, prism   \n",
       "\n",
       "                                             options      label  \n",
       "0  [mountain, volcano, hill, glacier, rock, climb...    volcano  \n",
       "1  [sunflower, daisy, rose, plant, summer, garden...  sunflower  \n",
       "2  [football, soccer, baseball, tennis, basketbal...   football  \n",
       "3  [firefly, dragonfly, moth, beetle, glow, lante...    firefly  \n",
       "4  [rainbow, weather, cloud, sun, spectrum, light...    rainbow  "
      ]
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1064",
     "meta": {},
     "output_type": "execute_result",
     "parent_header": {
      "date": "2025-07-17T08:36:34.222999Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1064",
      "msg_type": "execute_result",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    },
    {
     "data": {
      "execution_count": 131,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1065",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T08:36:34.218270Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T08:36:34.228795Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1065",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_txt_file(file_path):\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read().strip()\n",
    "    \n",
    "    blocks = content.split('\\n\\n')\n",
    "    \n",
    "    data = []\n",
    "    for block in blocks:\n",
    "        lines = block.strip().split('\\n')\n",
    "        if len(lines) < 5:\n",
    "            continue \n",
    "            \n",
    "        elif len(lines) == 5:\n",
    "            hint1 = lines[0].rstrip(';').strip()\n",
    "            hint2 = lines[1].rstrip(';').strip()\n",
    "            hint3 = lines[2].rstrip(';').strip()\n",
    "            \n",
    "            options = lines[3].strip()\n",
    "            options = options.strip('{}').replace(' ', '').split(',')\n",
    "            \n",
    "            label = lines[4].strip()\n",
    "            \n",
    "            data.append([hint1, hint2, hint3, options, label])\n",
    "            \n",
    "        elif len(lines) == 6:\n",
    "            \n",
    "            hint1 = lines[0].rstrip(';').strip()\n",
    "            hint2 = lines[1].rstrip(';').strip()\n",
    "            hint3 = lines[2].rstrip(';').strip()\n",
    "            \n",
    "            options = lines[4].strip()\n",
    "            options = options.strip('{}').replace(' ', '').split(',')\n",
    "            \n",
    "            label = lines[5].strip()\n",
    "            \n",
    "            data.append([hint1, hint2, hint3, options, label])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['hint1', 'hint2', 'hint3', 'options', 'label'])\n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = '/personal/2.txt'\n",
    "data = parse_txt_file(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "execution_count": 9,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_58",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T07:04:37.481740Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T07:04:37.484725Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_58",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "def all_possible_prompts_df(df, idx):\n",
    "    split_strings_list = []\n",
    "    prompt_list = []\n",
    "    for i in range (3):\n",
    "        hint = df.iloc[idx,i]\n",
    "        split_strings = hint.split(', ')\n",
    "        split_strings_list.append(split_strings)\n",
    "    cartesian = itertools.product(*split_strings_list)\n",
    "    for point in cartesian:\n",
    "         prompt_list.append(tuple_to_prompt(point))\n",
    "    return prompt_list\n",
    "    \n",
    "def give_best_prompt_df(df,idx):\n",
    "    prompts_list = all_possible_prompts_df(df,idx)    \n",
    "    embeddings = st_model.encode(prompts_list)\n",
    "    index = find_middle_sentence(embeddings)\n",
    "    best_prompt = prompts_list[index]\n",
    "    best_prompt = best_prompt.replace(\"A \", \"A [MASK] is a type of \")\n",
    "    return best_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "name": "stdout",
      "text": "[MASK] is a furniture connected to limb, and rest.\narmchair\n"
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_646",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-07-17T07:59:42.881941Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_646",
      "msg_type": "stream",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "[MASK] is a furniture connected to limb, and rest.\n",
      "armchair\n"
     ]
    },
    {
     "data": {
      "execution_count": 97,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_647",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T07:59:42.879091Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T07:59:42.882905Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_647",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "def hints_to_sentence_df(df,idx):\n",
    "    sentence = \"[MASK] is a \"\n",
    "    for i in range(3):\n",
    "        hint = df.iloc[idx,i]\n",
    "        split_strings = hint.split(', ')\n",
    "        if i == 0:\n",
    "            sentence += f\"{split_strings[0]}\"\n",
    "            sentence += \" connected to \"\n",
    "        elif i < 2:\n",
    "            sentence += f\"{split_strings[0]}\"\n",
    "            sentence += \", and \"\n",
    "        else:\n",
    "            sentence += f\"{split_strings[0]}\"\n",
    "            sentence += \".\"\n",
    "    sentence = sentence.replace('\\n', ', ')\n",
    "    return sentence\n",
    "\n",
    "def choice_to_doc(choice:str)->str: ### Label to prompt \n",
    "  return f\"Our target word: {choice}\"\n",
    "\n",
    "i=14\n",
    "print(hints_to_sentence_df(data,i))\n",
    "print(data.loc[i,'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "execution_count": 11,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_67",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T07:04:47.707006Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T07:04:47.710930Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_67",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "class LoRA(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=8, alpha=16):\n",
    "        super().__init__()\n",
    "        self.rank = rank  ### LoRA的秩（rank），控制低秩矩阵的大小\n",
    "        self.scaling = alpha ### 用来控制lora层的scaling参数\n",
    "        self.A = nn.Linear(in_features, rank, bias=False)  ### 低秩矩阵A\n",
    "        self.B = nn.Linear(rank, out_features, bias=False)  ### 低秩矩阵B\n",
    "        \n",
    "        self.A.weight.data.normal_(mean=0.0, std=0.02) ### 矩阵参数初始化\n",
    "        self.B.weight.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.B(self.A(x)) * self.scaling\n",
    "\n",
    "def apply_lora(model, rank=8):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear) and module.weight.shape[0] == module.weight.shape[1]:\n",
    "            lora = LoRA(module.weight.shape[0], module.weight.shape[1], rank=rank).to(model.device)\n",
    "            setattr(module, \"lora\", lora)\n",
    "            original_forward = module.forward\n",
    "\n",
    "            # 显式绑定\n",
    "            def forward_with_lora(x, layer1=original_forward, layer2=lora):\n",
    "                return layer1(x) + layer2(x)\n",
    "\n",
    "            module.forward = forward_with_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "execution_count": 181,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1594",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T09:27:52.084674Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T09:27:52.089189Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1594",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,data,tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sentence = hints_to_sentence_df(self.data,idx)\n",
    "        candidate = self.data.loc[idx,'options']\n",
    "        label = self.data.loc[idx,'label']\n",
    "        \n",
    "        sentence = tokenizer(sentence, return_tensors='pt',padding='max_length',max_length=50)\n",
    "        \n",
    "        padding_length = 60 - len(candidate)\n",
    "        candidate = candidate + [tokenizer.pad_token] * padding_length\n",
    "        candidate = np.array([tokenizer.convert_tokens_to_ids(word) for word in candidate])\n",
    "        \n",
    "        label = tokenizer.convert_tokens_to_ids(label) #tokenizer(label, return_tensors='pt',padding='max_length',max_length=8)[\"input_ids\"][0]\n",
    "\n",
    "        return sentence, candidate, label\n",
    "\n",
    "class MyDataset_DS(torch.utils.data.Dataset):\n",
    "    def __init__(self,data,tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sentence = hints_to_sentence_ori(self.data[idx]['hints'])\n",
    "        candidate = self.data[idx]['options']\n",
    "        label = self.data[idx]['label']\n",
    "        \n",
    "        sentence = tokenizer(sentence, return_tensors='pt',padding='max_length',max_length=50)\n",
    "        \n",
    "        padding_length = 60 - len(candidate)\n",
    "        candidate = candidate + [tokenizer.pad_token] * padding_length\n",
    "        candidate = np.array([tokenizer.convert_tokens_to_ids(word) for word in candidate])\n",
    "        \n",
    "        label = tokenizer.convert_tokens_to_ids(label) #tokenizer(label, return_tensors='pt',padding='max_length',max_length=8)[\"input_ids\"][0]\n",
    "\n",
    "        return sentence, candidate, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "execution_count": 234,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_2253",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T09:55:46.508796Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T09:55:46.514608Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_2253",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "def train_model(model, loader, epochs=3, learning_rate=5e-5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    log1=[]\n",
    "    log2=[]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        train_loss = 0\n",
    "        \n",
    "        for sentence, candidate, label in loader:\n",
    "            \n",
    "            sentence = sentence.to(device)\n",
    "            sentence = {k: v.squeeze(1).to(device) for k, v in sentence.items()}\n",
    "            outputs = model(**sentence)\n",
    "            logits = outputs.logits\n",
    "            label = label.to(device)\n",
    "            candidate = candidate.to(device)\n",
    "\n",
    "            mask_token_index = [torch.where(sentence['input_ids'][i] == tokenizer.mask_token_id)[0] for i in range(label.size(0))]\n",
    "            mask_logits = logits[torch.arange(label.size(0)), mask_token_index, :].squeeze()\n",
    "\n",
    "            candidate_logits = torch.gather(mask_logits, \n",
    "                                            dim=1, \n",
    "                                            index=candidate.to(dtype=torch.int64)\n",
    "                               )\n",
    "\n",
    "            probs = torch.softmax(candidate_logits, dim=-1)\n",
    "\n",
    "            label_probs = torch.zeros_like(probs)\n",
    "            for i in range (label.size(0)):\n",
    "                sample1 = candidate[i]\n",
    "                label1 = label[i]\n",
    "                indeces = torch.where(sample1==label1)\n",
    "                for idx in indeces:\n",
    "                    label_probs[i,idx]=1\n",
    "\n",
    "            loss = criterion(probs, label_probs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "        total_scores=0\n",
    "        for example in test_dataset:\n",
    "            result_list = BERTTopKMaskWord(hints_to_sentence_ori(example['hints']),example['options'])\n",
    "            total_scores += score(result_list, example['label'])['total_score']\n",
    "        print(f\"Train Loss: {train_loss:.8f},     \"+f\"Average validation score: {total_scores*2 / len(validation_data)}\")\n",
    "        log1.append(train_loss)\n",
    "        log2.append(total_scores/len(validation_data))\n",
    "    return log1, log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "name": "stderr",
      "text": "Some weights of the model checkpoint at /personal/bert-large-uncased/ were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_2498",
     "meta": {},
     "name": "stderr",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-07-17T10:55:23.412864Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_2498",
      "msg_type": "stream",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "Some weights of the model checkpoint at /personal/bert-large-uncased/ were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "execution_count": 245,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_2499",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T10:55:22.165047Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T10:55:23.513465Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_2499",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "model_dir = '/personal/bert-large-uncased/'\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "apply_lora(model,rank=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "execution_count": 108,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_740",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T08:05:48.503694Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T08:05:48.506551Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_740",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "def print_model_layers(model, indent=0):\n",
    "    for name, module in model.named_children():\n",
    "        print(\"  \" * indent + f\"{name}: {module.__class__.__name__}\")\n",
    "        if len(list(module.parameters())) > 0:\n",
    "            param = next(module.parameters())\n",
    "            print(\"  \" * (indent + 1) + f\"requires_grad={param.requires_grad}\")\n",
    "        if len(list(module.named_children())) > 0:\n",
    "            print_model_layers(module, indent + 2)           \n",
    "#print_model_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "name": "stdout",
      "text": "20\n"
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1579",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-07-17T09:26:23.617438Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1579",
      "msg_type": "stream",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "execution_count": 178,
      "payload": [],
      "status": "ok",
      "user_expressions": {}
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1580",
     "meta": {
      "dependencies_met": true,
      "engine": "d5987e15-b367-4187-8366-05935e64c9d4",
      "started": "2025-07-17T09:26:23.612404Z",
      "status": "ok"
     },
     "output_type": "execute_reply",
     "parent_header": {
      "date": "2025-07-17T09:26:23.618372Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_1580",
      "msg_type": "execute_reply",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     }
    }
   ],
   "source": [
    "print(len(validation_data))\n",
    "train_indices = [i for i in range(len(validation_data)) if i % 2 == 0]\n",
    "test_indices = [i for i in range(len(validation_data)) if i % 2 != 0]\n",
    "train_dataset = validation_data.select(train_indices)\n",
    "test_dataset = validation_data.select(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "name": "stdout",
      "text": "Train Loss: 0.15484826,     Average validation score: 0.7674806539156965\n"
     },
     "id": "33be4e9c-9c29d957578c4b5031ed0786_8433_2503",
     "meta": {},
     "name": "stdout",
     "output_type": "stream",
     "parent_header": {
      "date": "2025-07-17T10:55:28.078263Z",
      "msg_id": "33be4e9c-9c29d957578c4b5031ed0786_8433_2503",
      "msg_type": "stream",
      "session": "33be4e9c-9c29d957578c4b5031ed0786",
      "username": "username",
      "version": "5.3"
     },
     "text": [
      "Train Loss: 0.15484826,     Average validation score: 0.7674806539156965\n",
      "Train Loss: 0.14796567,     Average validation score: 0.7687913567695278\n"
     ]
    }
   ],
   "source": [
    "mydataset = MyDataset_DS(train_dataset,tokenizer)\n",
    "loader = DataLoader(mydataset,batch_size=5,shuffle=True)\n",
    "losslog, scorelog = train_model(model,loader,epochs=30,learning_rate=5e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
