{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ff00b-1364-47fd-a83e-91ff345a21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super(SeparableConv2d, self)._init_()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, padding, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, dilation):\n",
    "    kernel_size_effective = kernel_size + (kernel_size - 1) * (dilation - 1)\n",
    "    pad_total = kernel_size_effective - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    padded_inputs = F.pad(inputs, (pad_beg, pad_end, pad_beg, pad_end))\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "class SeparableConv2d_same(nn.Module):\n",
    "    def __init__(self, inplanes, planes, kernel_size=3, stride=1, dilation=1, bias=False):\n",
    "        super(SeparableConv2d_same, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, inplanes, kernel_size, stride, 0, dilation,\n",
    "                               groups=inplanes, bias=bias)\n",
    "        self.pointwise = nn.Conv2d(inplanes, planes, 1, 1, 0, 1, 1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = fixed_padding(x, self.conv1.kernel_size[0], dilation=self.conv1.dilation[0])\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, inplanes, planes, reps, stride=1, dilation=1, start_with_relu=True, grow_first=True, is_last=False):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        if planes != inplanes or stride != 1:\n",
    "            self.skip = nn.Conv2d(inplanes, planes, 1, stride=stride, bias=False)\n",
    "            self.skipbn = BatchNorm2d(planes)\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep = []\n",
    "\n",
    "        filters = inplanes\n",
    "        if grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d_same(inplanes, planes, 3, stride=1, dilation=dilation))\n",
    "            rep.append(BatchNorm2d(planes))\n",
    "            filters = planes\n",
    "\n",
    "        for i in range(reps - 1):\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d_same(filters, filters, 3, stride=1, dilation=dilation))\n",
    "            rep.append(BatchNorm2d(filters))\n",
    "\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d_same(inplanes, planes, 3, stride=1, dilation=dilation))\n",
    "            rep.append(BatchNorm2d(planes))\n",
    "\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "\n",
    "        if stride != 1:\n",
    "            rep.append(SeparableConv2d_same(planes, planes, 3, stride=2))\n",
    "\n",
    "        if stride == 1 and is_last:\n",
    "            rep.append(SeparableConv2d_same(planes, planes, 3, stride=1))\n",
    "\n",
    "\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.rep(inp)\n",
    "\n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(inp)\n",
    "            skip = self.skipbn(skip)\n",
    "        else:\n",
    "            skip = inp\n",
    "\n",
    "        x += skip\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Xception(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified Alighed Xception\n",
    "    \"\"\"\n",
    "    def __init__(self, inplanes=3, os=16, pretrained=False):\n",
    "        super(Xception, self).__init__()\n",
    "\n",
    "        if os == 16:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_dilation = 1\n",
    "            exit_block_dilations = (1, 2)\n",
    "        elif os == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_dilation = 2\n",
    "            exit_block_dilations = (2, 4)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "        # Entry flow\n",
    "        self.conv1 = nn.Conv2d(inplanes, 32, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(64)\n",
    "\n",
    "        self.block1 = Block(64, 128, reps=2, stride=2, start_with_relu=False)\n",
    "        self.block2 = Block(128, 256, reps=2, stride=2, start_with_relu=True, grow_first=True)\n",
    "        self.block3 = Block(256, 728, reps=2, stride=entry_block3_stride, start_with_relu=True, grow_first=True,\n",
    "                            is_last=True)\n",
    "\n",
    "        # Middle flow\n",
    "        self.block4  = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block5  = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block6  = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block7  = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block8  = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block9  = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        '''\n",
    "        self.block10 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block11 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block12 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block13 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block14 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block15 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block16 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block17 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block18 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        self.block19 = Block(728, 728, reps=3, stride=1, dilation=middle_block_dilation, start_with_relu=True, grow_first=True)\n",
    "        '''\n",
    "\n",
    "        # Exit flow\n",
    "        self.block20 = Block(728, 1024, reps=2, stride=1, dilation=exit_block_dilations[0],\n",
    "                             start_with_relu=True, grow_first=False, is_last=True)\n",
    "\n",
    "        self.conv3 = SeparableConv2d_same(1024, 1536, 3, stride=1, dilation=exit_block_dilations[1])\n",
    "        self.bn3 = BatchNorm2d(1536)\n",
    "\n",
    "        self.conv4 = SeparableConv2d_same(1536, 1536, 3, stride=1, dilation=exit_block_dilations[1])\n",
    "        self.bn4 = BatchNorm2d(1536)\n",
    "\n",
    "        self.conv5 = SeparableConv2d_same(1536, 2048, 3, stride=1, dilation=exit_block_dilations[1])\n",
    "        self.bn5 = BatchNorm2d(2048)\n",
    "\n",
    "        # Init weights\n",
    "        self._init_weight()\n",
    "\n",
    "        # Load pretrained model\n",
    "        if pretrained:\n",
    "            self._load_xception_pretrained()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Entry flow\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        low_level_feat = x\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "\n",
    "        # Middle flow\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.block9(x)\n",
    "        '''\n",
    "        x = self.block10(x)\n",
    "        x = self.block11(x)\n",
    "        x = self.block12(x)\n",
    "        x = self.block13(x)\n",
    "        x = self.block14(x)\n",
    "        x = self.block15(x)\n",
    "        x = self.block16(x)\n",
    "        x = self.block17(x)\n",
    "        x = self.block18(x)\n",
    "        x = self.block19(x)\n",
    "        '''\n",
    "\n",
    "        # Exit flow\n",
    "        x = self.block20(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _load_xception_pretrained(self):\n",
    "            pretrain_dict = torch.load('/personal/预训练模型/Xception.pth')\n",
    "            model_dict = {}\n",
    "            state_dict = self.state_dict()\n",
    "    \n",
    "            for k, v in pretrain_dict.items():\n",
    "                if k in model_dict:\n",
    "                    if 'pointwise' in k:\n",
    "                        v = v.unsqueeze(-1).unsqueeze(-1)\n",
    "                    if k.startswith('block11'):\n",
    "                        model_dict[k] = v\n",
    "                        model_dict[k.replace('block11', 'block12')] = v\n",
    "                        model_dict[k.replace('block11', 'block13')] = v\n",
    "                        model_dict[k.replace('block11', 'block14')] = v\n",
    "                        model_dict[k.replace('block11', 'block15')] = v\n",
    "                        model_dict[k.replace('block11', 'block16')] = v\n",
    "                        model_dict[k.replace('block11', 'block17')] = v\n",
    "                        model_dict[k.replace('block11', 'block18')] = v\n",
    "                        model_dict[k.replace('block11', 'block19')] = v\n",
    "                    elif k.startswith('block12'):\n",
    "                        model_dict[k.replace('block12', 'block20')] = v\n",
    "                    elif k.startswith('bn3'):\n",
    "                        model_dict[k] = v\n",
    "                        model_dict[k.replace('bn3', 'bn4')] = v\n",
    "                    elif k.startswith('conv4'):\n",
    "                        model_dict[k.replace('conv4', 'conv5')] = v\n",
    "                    elif k.startswith('bn4'):\n",
    "                        model_dict[k.replace('bn4', 'bn5')] = v\n",
    "                    else:\n",
    "                        model_dict[k] = v\n",
    "            state_dict.update(model_dict)\n",
    "            self.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "class ASPP_module(nn.Module):\n",
    "    def __init__(self, inplanes, planes, dilation):\n",
    "        super(ASPP_module, self).__init__()\n",
    "        if dilation == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = dilation\n",
    "        self.atrous_convolution = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                                            stride=1, padding=padding, dilation=dilation, bias=False)\n",
    "        self.bn = BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class DeepLabv3_plus(nn.Module):\n",
    "    def __init__(self, nInputChannels=3, n_classes=21, os=16, pretrained=False, freeze_bn=False, _print=True):\n",
    "        if _print:\n",
    "            print(\"Constructing DeepLabv3+ model...\")\n",
    "            print(\"Backbone: Xception\")\n",
    "            print(\"Number of classes: {}\".format(n_classes))\n",
    "            print(\"Output stride: {}\".format(os))\n",
    "            print(\"Number of Input Channels: {}\".format(nInputChannels))\n",
    "        super(DeepLabv3_plus, self).__init__()\n",
    "\n",
    "        # Atrous Conv\n",
    "        self.xception_features = Xception(nInputChannels, os, pretrained)\n",
    "\n",
    "        # ASPP\n",
    "        if os == 16:\n",
    "            dilations = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            dilations = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.aspp1 = ASPP_module(2048, 256, dilation=dilations[0])\n",
    "        self.aspp2 = ASPP_module(2048, 256, dilation=dilations[1])\n",
    "        self.aspp3 = ASPP_module(2048, 256, dilation=dilations[2])\n",
    "        self.aspp4 = ASPP_module(2048, 256, dilation=dilations[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((2, 2)),\n",
    "                                             nn.Conv2d(2048, 256, 1, stride=1, bias=False),\n",
    "                                             BatchNorm2d(256),\n",
    "                                             nn.ReLU())\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(256)\n",
    "\n",
    "        # adopt [1x1, 48] for channel reduction.\n",
    "        self.conv2 = nn.Conv2d(128, 48, 1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(48)\n",
    "\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(0.5),\n",
    "                                       nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(0.1),\n",
    "                                       nn.Conv2d(256, n_classes, kernel_size=1, stride=1))\n",
    "        if freeze_bn:\n",
    "            self._freeze_bn()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x, low_level_features = self.xception_features(input)\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.interpolate(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.interpolate(x, size=(int(math.ceil(input.size()[-2]/4)),\n",
    "                                int(math.ceil(input.size()[-1]/4))), mode='bilinear', align_corners=True)\n",
    "\n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.interpolate(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f531c-84cb-4bd1-af38-7bd7b9aaafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception = model_zoo.load_url('http://data.lip6.fr/cadene/pretrainedmodels/xception-b5690688.pth')\n",
    "torch.save(Xception, '/personal/预训练模型/Xception.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da2ca9-e6d5-4963-915c-eed6a5846777",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabv3_plus(nInputChannels=1, n_classes=1, os=16, pretrained=True, freeze_bn=False, _print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f33b1-1fe7-464c-85d8-c29f92f76c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ca91e-0df8-407a-9723-d5e883c2e6d0",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655927c7-3cb5-4e41-b7bb-747ab0567063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AstroDataset(Dataset):\n",
    "    def __init__(self, map_paths, cat_paths=None):\n",
    "        self.map_paths = map_paths\n",
    "        self.cat_paths = cat_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.map_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image with gaussian smoothing\n",
    "        map_data = gaussian_filter(pyfits.open(self.map_paths[idx])[0].data, sigma=SMOOTHING)\n",
    "        \n",
    "        if self.cat_paths is None:\n",
    "            return torch.FloatTensor(map_data).unsqueeze(0)\n",
    "\n",
    "        # Load catalog\n",
    "        cat = pyfits.open(self.cat_paths[idx])[0].data\n",
    "        target = np.zeros((1024, 1024))\n",
    "\n",
    "        for y, x in cat[:, 1:3]:\n",
    "            target[int(y), int(x)] = 1.0\n",
    "\n",
    "        return torch.FloatTensor(map_data).unsqueeze(0), torch.FloatTensor(target), self.cat_paths[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3971a59-506e-413f-8cbe-db40e629058c",
   "metadata": {},
   "source": [
    "### Model and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ceeda-ec9f-48d5-b999-22b28ce939a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "\n",
    "# Function for applicating model results\n",
    "def detect_objects(model, image_path, confidence_threshold, device=DEVICE):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Load and preprocess image\n",
    "        map_data = gaussian_filter(pyfits.open(image_path)[0].data, sigma=SMOOTHING)\n",
    "        image = torch.FloatTensor(map_data).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        output = model(image)\n",
    "        output = torch.sigmoid(output)\n",
    "        predictions = output.cpu().squeeze().numpy()\n",
    "        \n",
    "        # Convert to coordinates\n",
    "        coordinates = []\n",
    "        for y, x in zip(*np.where(predictions > confidence_threshold)):\n",
    "            confidence = predictions[y, x]\n",
    "            coordinates.append((x, y, confidence))\n",
    "            \n",
    "        return coordinates\n",
    "\n",
    "# Visualizing model predictions\n",
    "def visualize_results(model, image_path, label_path, confidence_threshold, device=DEVICE):\n",
    "    # Get predictions with confidence scores\n",
    "    results = detect_objects(model, image_path, confidence_threshold, device)\n",
    "    results = np.array(results).T if results else np.array([[],[],[]])\n",
    "    \n",
    "    Z = pyfits.open(image_path)[0].data\n",
    "    Z_smooth = gaussian_filter(Z, sigma=SMOOTHING)\n",
    "    \n",
    "    labels = np.transpose(pyfits.open(label_path)[0].data)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(Z_smooth, vmin=-0.1, vmax=0.2, cmap='binary')\n",
    "    plt.scatter(labels[2], labels[1], facecolors='none', edgecolors='red', s=100, label=\"True\")\n",
    "    if len(results[0]) > 0:\n",
    "        # Color the scatter points based on confidence scores\n",
    "        plt.scatter(results[0], results[1], facecolors='none', edgecolors='green', s=100, label=\"Predicted\")\n",
    "    else:\n",
    "        print(\"result length 0\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "Metric function for calculating PR-AUC.\n",
    "This exact function will be used for evaluation\n",
    "'''\n",
    "def calculate_precision_recall_curve(predictions, labels, verbose = True):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"shape of predictions: \", predictions.shape)\n",
    "\n",
    "    # Flatten the predictions and get the indices of the sorted predictions\n",
    "    flat_predictions = predictions.flatten()\n",
    "    sorted_indices = np.argsort(-flat_predictions)  # Sort in descending order\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    true_preds = 0\n",
    "    num_preds = 0\n",
    "    predicted_labels = 0\n",
    "    num_labels = sum(len(l) for l in labels)\n",
    "\n",
    "    labels_within_distance = [[] for _ in range(len(flat_predictions))]\n",
    "\n",
    "    i = 0\n",
    "    for image_idx, image_labels in enumerate(labels):\n",
    "        for y_true, x_true in image_labels:\n",
    "            for y in range(max(0, int(y_true) - 15), min(1024, int(y_true) + 16)):\n",
    "                # Calculate the maximum x distance for the current y\n",
    "                max_x_dist = int((max(0, 15**2 - (y - y_true)**2))**0.5)\n",
    "                # Calculate the range of x-coordinates\n",
    "                for x in range(max(0, int(x_true) - max_x_dist), min(1024, int(x_true) + max_x_dist + 1)):\n",
    "                    coord_idx = image_idx * 1024 * 1024 + y * 1024 + x\n",
    "                    labels_within_distance[coord_idx].append(i)\n",
    "            i += 1\n",
    "    \n",
    "    label_predicted = [False] * num_labels\n",
    "\n",
    "    # Iterate over sorted predictions\n",
    "    for idx in sorted_indices:\n",
    "\n",
    "        num_preds += 1\n",
    "\n",
    "        # Determine the image index and the coordinate within the image\n",
    "        image_idx = idx // (1024 * 1024)\n",
    "        coord_idx = idx % (1024 * 1024)\n",
    "        y, x = divmod(coord_idx, 1024)\n",
    "\n",
    "        if len(labels_within_distance[idx]) > 0:\n",
    "            true_preds += 1\n",
    "            for label in labels_within_distance[idx]:\n",
    "                if label_predicted[label] is False:\n",
    "                    label_predicted[label] = True\n",
    "                    predicted_labels += 1\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        precision = true_preds / num_preds\n",
    "        recall = predicted_labels / num_labels\n",
    "\n",
    "        # Append precision and recall to the lists\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    # Calculate PR-AUC using the trapezoidal rule\n",
    "    pr_auc = np.trapz(precisions, x=recalls)\n",
    "\n",
    "    return precisions, recalls, pr_auc\n",
    "\n",
    "# Evaluate model\n",
    "def get_pr(model, test_loader, device=DEVICE, verbose=True):\n",
    "    model.eval()\n",
    "    outputs_list = []\n",
    "    labels_list = []\n",
    "    for images, _, paths in test_loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            outputs = torch.sigmoid(model(images)).cpu().numpy().squeeze(1)\n",
    "            outputs_list.append(outputs)\n",
    "            cat_data = [np.transpose(pyfits.open(path)[0].data) for path in paths]\n",
    "            labels = [list(zip(cat[1], cat[2])) for cat in cat_data]\n",
    "            labels_list += labels\n",
    "    outputs = np.concat(outputs_list,axis=0)\n",
    "    return calculate_precision_recall_curve(outputs, labels_list, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3668d83-c937-44f2-9c78-80a192e04a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to training data *** do not change *** \n",
    "DATA_DIR = \"/bohr/training-lg02/v1/\"\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "MODEL_SAVE_PATH = \"model.pth\"\n",
    "\n",
    "SMOOTHING = 3\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "data_size = len(os.listdir(os.path.join(DATA_DIR, 'map')))\n",
    "dataset = AstroDataset([os.path.join(DATA_DIR, f'map/{i}.fits') for i in range(1, 56+1)], [os.path.join(DATA_DIR, f'cat/{i}.fits') for i in range(1, 56+1)])\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_set = AstroDataset([os.path.join(DATA_DIR, f'map/{i}.fits') for i in range(57, data_size+1)], [os.path.join(DATA_DIR, f'cat/{i}.fits') for i in range(57, data_size+1)])\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb76f68-bd4c-42a1-abef-561cb485ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "LEARNING_RATE = 0.0003\n",
    "\n",
    "weight = torch.tensor([99.0]).cuda()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "model.cuda()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, targets, _ in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze(1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    train_loss = total_loss/len(dataloader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    _, _, pr_auc = get_pr(model, test_loader, verbose=False)\n",
    "\n",
    "    if (epoch+1)%1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Training Loss: {train_loss:.6f}, Test AUC: {pr_auc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fe7467-e219-4f42-b743-c9d973798422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curve\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073798f-8166-489b-9b99-f2fa28c4a175",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70123c08-72dc-4574-a023-16ac14e1ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 13\n",
    "visualize_results(model, test_set.map_paths[i], test_set.cat_paths[i], confidence_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53446661-1613-4dc1-8ccc-6395ca6fb1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PR-AUC\n",
    "precisions, recalls, pr_auc = get_pr(model, test_loader)\n",
    "print(f\"PR-AUC Score: {pr_auc:.4f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curve (AUC = {pr_auc:.4f})')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
