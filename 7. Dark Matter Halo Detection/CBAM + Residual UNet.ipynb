{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f33b1-1fe7-464c-85d8-c29f92f76c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ff00b-1364-47fd-a83e-91ff345a21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CBAM Block\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # 全局平均池化\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)  # 全局最大池化\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction_ratio, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction_ratio, in_channels, 1)\n",
    "        )\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.mlp[0].weight)\n",
    "        nn.init.zeros_(self.mlp[0].bias)\n",
    "        nn.init.kaiming_normal_(self.mlp[2].weight)\n",
    "        nn.init.zeros_(self.mlp[2].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.mlp(self.avg_pool(x))\n",
    "        max_out = self.mlp(self.max_pool(x))\n",
    "        out = avg_out + max_out  # 通道特征融合\n",
    "        return torch.sigmoid(out)  # 输出归一化权重\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        assert kernel_size in (3, 7), \"kernel size should be 3 or 7\"\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)  # 平均响应\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # 最大响应\n",
    "        concat = torch.cat([avg_out, max_out], dim=1)  # 特征拼接\n",
    "        out = self.conv(concat)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(in_channels, reduction_ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.ca(x)\n",
    "        return x * self.sa(x)\n",
    "\n",
    "### ResNet Convolution Block\n",
    "class ResidualConv(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, stride=1, padding=1):\n",
    "      super().__init__()\n",
    "      self.conv_block = nn.Sequential(\n",
    "          nn.BatchNorm2d(input_dim), nn.ReLU(),\n",
    "          nn.Conv2d(input_dim, output_dim, kernel_size=3, stride=stride, padding=padding),\n",
    "          nn.BatchNorm2d(output_dim), nn.ReLU(),\n",
    "          nn.Conv2d(output_dim, output_dim, kernel_size=3, padding=1)\n",
    "      )\n",
    "      self.conv_skip = nn.Sequential(\n",
    "          nn.Conv2d(input_dim, output_dim, kernel_size=3, stride=stride, padding=1),\n",
    "          nn.BatchNorm2d(output_dim)\n",
    "      )\n",
    "  def forward(self, x):\n",
    "      return self.conv_block(x) + self.conv_skip(x)\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, in_channels=1, d=32,dp=0.5):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.dp = dp\n",
    "        self.encoder1 = ResidualConv(in_channels, d)\n",
    "        self.encoder2 = ResidualConv(d, d*2)\n",
    "        self.encoder3 = ResidualConv(d*2, d*4)\n",
    "        self.encoder4 = ResidualConv(d*4, d*8)\n",
    "        self.encoder5 = ResidualConv(d*8, d*16)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.mid = self.conv_block(d*16, d*32)\n",
    "        \n",
    "        self.up5 = nn.ConvTranspose2d(d*32, d*16, 2, stride=2)\n",
    "        self.dec5 = self.conv_block(d*32, d*16)\n",
    "        self.up4 = nn.ConvTranspose2d(d*16, d*8, 2, stride=2)\n",
    "        self.dec4 = self.conv_block(d*16, d*8)\n",
    "        self.up3 = nn.ConvTranspose2d(d*8, d*4, 2, stride=2)\n",
    "        self.dec3 = self.conv_block(d*8, d*4)\n",
    "        self.up2 = nn.ConvTranspose2d(d*4, d*2, 2, stride=2)\n",
    "        self.dec2 = self.conv_block(d*4, d*2)\n",
    "        self.up1 = nn.ConvTranspose2d(d*2, d, 2, stride=2)\n",
    "        self.dec1 = self.conv_block(d*2, d)\n",
    "\n",
    "        self.final = nn.Conv2d(d, 1, kernel_size=1)\n",
    "\n",
    "        self.cbam4 = CBAM(d*8)\n",
    "        self.cbam2 = CBAM(d*2)\n",
    "        self.cbam0 = CBAM(d)\n",
    "\n",
    "    def conv_block(self, in_ch, out_ch):\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(self.dp),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(self.dp)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool(e1))\n",
    "        e3 = self.encoder3(self.pool(e2))\n",
    "        e4 = self.encoder4(self.pool(e3))\n",
    "        e5 = self.encoder5(self.pool(e4))\n",
    "        \n",
    "        m = self.mid(self.pool(e5))\n",
    "\n",
    "        d5 = self.dec5(torch.cat([self.up5(m), e5], dim=1))\n",
    "        d4 = self.dec4(torch.cat([self.up4(d5), e4], dim=1))\n",
    "        d4 = self.cbam4(d4)\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d2 = self.cbam2(d2)\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "        d1 = self.cbam0(d1)\n",
    "\n",
    "        out = self.final(d1)  \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ca91e-0df8-407a-9723-d5e883c2e6d0",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655927c7-3cb5-4e41-b7bb-747ab0567063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AstroDataset(Dataset):\n",
    "    def __init__(self, map_paths, cat_paths=None):\n",
    "        self.map_paths = map_paths\n",
    "        self.cat_paths = cat_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.map_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image with gaussian smoothing\n",
    "        map_data = gaussian_filter(pyfits.open(self.map_paths[idx])[0].data, sigma=SMOOTHING)\n",
    "        \n",
    "        if self.cat_paths is None:\n",
    "            return torch.FloatTensor(map_data).unsqueeze(0)\n",
    "\n",
    "        # Load catalog\n",
    "        cat = pyfits.open(self.cat_paths[idx])[0].data\n",
    "        target = np.zeros((1024, 1024))\n",
    "\n",
    "        for y, x in cat[:, 1:3]:\n",
    "            target[int(y), int(x)] = 1.0\n",
    "\n",
    "        return torch.FloatTensor(map_data).unsqueeze(0), torch.FloatTensor(target), self.cat_paths[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3971a59-506e-413f-8cbe-db40e629058c",
   "metadata": {},
   "source": [
    "### Model and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ceeda-ec9f-48d5-b999-22b28ce939a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "\n",
    "# Function for applicating model results\n",
    "def detect_objects(model, image_path, confidence_threshold, device=DEVICE):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Load and preprocess image\n",
    "        map_data = gaussian_filter(pyfits.open(image_path)[0].data, sigma=SMOOTHING)\n",
    "        image = torch.FloatTensor(map_data).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        output = model(image)\n",
    "        output = torch.sigmoid(output)\n",
    "        predictions = output.cpu().squeeze().numpy()\n",
    "        \n",
    "        # Convert to coordinates\n",
    "        coordinates = []\n",
    "        for y, x in zip(*np.where(predictions > confidence_threshold)):\n",
    "            confidence = predictions[y, x]\n",
    "            coordinates.append((x, y, confidence))\n",
    "            \n",
    "        return coordinates\n",
    "\n",
    "# Visualizing model predictions\n",
    "def visualize_results(model, image_path, label_path, confidence_threshold, device=DEVICE):\n",
    "    # Get predictions with confidence scores\n",
    "    results = detect_objects(model, image_path, confidence_threshold, device)\n",
    "    results = np.array(results).T if results else np.array([[],[],[]])\n",
    "    \n",
    "    Z = pyfits.open(image_path)[0].data\n",
    "    Z_smooth = gaussian_filter(Z, sigma=SMOOTHING)\n",
    "    \n",
    "    labels = np.transpose(pyfits.open(label_path)[0].data)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(Z_smooth, vmin=-0.1, vmax=0.2, cmap='binary')\n",
    "    plt.scatter(labels[2], labels[1], facecolors='none', edgecolors='red', s=100, label=\"True\")\n",
    "    if len(results[0]) > 0:\n",
    "        # Color the scatter points based on confidence scores\n",
    "        plt.scatter(results[0], results[1], facecolors='none', edgecolors='green', s=100, label=\"Predicted\")\n",
    "    else:\n",
    "        print(\"result length 0\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "Metric function for calculating PR-AUC.\n",
    "This exact function will be used for evaluation\n",
    "'''\n",
    "def calculate_precision_recall_curve(predictions, labels, verbose = True):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"shape of predictions: \", predictions.shape)\n",
    "\n",
    "    # Flatten the predictions and get the indices of the sorted predictions\n",
    "    flat_predictions = predictions.flatten()\n",
    "    sorted_indices = np.argsort(-flat_predictions)  # Sort in descending order\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    true_preds = 0\n",
    "    num_preds = 0\n",
    "    predicted_labels = 0\n",
    "    num_labels = sum(len(l) for l in labels)\n",
    "\n",
    "    labels_within_distance = [[] for _ in range(len(flat_predictions))]\n",
    "\n",
    "    i = 0\n",
    "    for image_idx, image_labels in enumerate(labels):\n",
    "        for y_true, x_true in image_labels:\n",
    "            for y in range(max(0, int(y_true) - 15), min(1024, int(y_true) + 16)):\n",
    "                # Calculate the maximum x distance for the current y\n",
    "                max_x_dist = int((max(0, 15**2 - (y - y_true)**2))**0.5)\n",
    "                # Calculate the range of x-coordinates\n",
    "                for x in range(max(0, int(x_true) - max_x_dist), min(1024, int(x_true) + max_x_dist + 1)):\n",
    "                    coord_idx = image_idx * 1024 * 1024 + y * 1024 + x\n",
    "                    labels_within_distance[coord_idx].append(i)\n",
    "            i += 1\n",
    "    \n",
    "    label_predicted = [False] * num_labels\n",
    "\n",
    "    # Iterate over sorted predictions\n",
    "    for idx in sorted_indices:\n",
    "\n",
    "        num_preds += 1\n",
    "\n",
    "        # Determine the image index and the coordinate within the image\n",
    "        image_idx = idx // (1024 * 1024)\n",
    "        coord_idx = idx % (1024 * 1024)\n",
    "        y, x = divmod(coord_idx, 1024)\n",
    "\n",
    "        if len(labels_within_distance[idx]) > 0:\n",
    "            true_preds += 1\n",
    "            for label in labels_within_distance[idx]:\n",
    "                if label_predicted[label] is False:\n",
    "                    label_predicted[label] = True\n",
    "                    predicted_labels += 1\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        precision = true_preds / num_preds\n",
    "        recall = predicted_labels / num_labels\n",
    "\n",
    "        # Append precision and recall to the lists\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    # Calculate PR-AUC using the trapezoidal rule\n",
    "    pr_auc = np.trapz(precisions, x=recalls)\n",
    "\n",
    "    return precisions, recalls, pr_auc\n",
    "\n",
    "# Evaluate model\n",
    "def get_pr(model, test_loader, device=DEVICE, verbose=True):\n",
    "    model.eval()\n",
    "    outputs_list = []\n",
    "    labels_list = []\n",
    "    for images, _, paths in test_loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            outputs = torch.sigmoid(model(images)).cpu().numpy().squeeze(1)\n",
    "            outputs_list.append(outputs)\n",
    "            cat_data = [np.transpose(pyfits.open(path)[0].data) for path in paths]\n",
    "            labels = [list(zip(cat[1], cat[2])) for cat in cat_data]\n",
    "            labels_list += labels\n",
    "    outputs = np.concat(outputs_list,axis=0)\n",
    "    return calculate_precision_recall_curve(outputs, labels_list, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3668d83-c937-44f2-9c78-80a192e04a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to training data *** do not change *** \n",
    "DATA_DIR = \"/bohr/training-lg02/v1/\"\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "MODEL_SAVE_PATH = \"model.pth\"\n",
    "\n",
    "SMOOTHING = 0.0\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "data_size = len(os.listdir(os.path.join(DATA_DIR, 'map')))\n",
    "dataset = AstroDataset([os.path.join(DATA_DIR, f'map/{i}.fits') for i in range(1, 56+1)], [os.path.join(DATA_DIR, f'cat/{i}.fits') for i in range(1, 56+1)])\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_set = AstroDataset([os.path.join(DATA_DIR, f'map/{i}.fits') for i in range(57, data_size+1)], [os.path.join(DATA_DIR, f'cat/{i}.fits') for i in range(57, data_size+1)])\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb76f68-bd4c-42a1-abef-561cb485ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model in locals():\n",
    "    del model\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.003\n",
    "\n",
    "model = MyModel()\n",
    "weight = torch.tensor([1000.0]).cuda()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "model.cuda()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, targets, _ in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze(1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    train_loss = total_loss/len(dataloader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    _, _, test_auc = get_pr(model, dataloader, verbose=False)\n",
    "    _, _, train_auc = get_pr(model, test_loader, verbose=False)\n",
    "\n",
    "    if (epoch+1)%1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Training Loss: {train_loss:.6f}, Train AUC: {train_auc:.6f}, Test AUC: {test_auc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073798f-8166-489b-9b99-f2fa28c4a175",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70123c08-72dc-4574-a023-16ac14e1ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 30\n",
    "visualize_results(model, dataset.map_paths[i], dataset.cat_paths[i], confidence_threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
