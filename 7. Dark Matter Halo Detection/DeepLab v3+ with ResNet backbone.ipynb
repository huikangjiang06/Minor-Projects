{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ff00b-1364-47fd-a83e-91ff345a21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "BatchNorm2d = nn.BatchNorm2d\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               dilation=dilation, padding=dilation, bias=False)\n",
    "        self.bn2 = BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nInputChannels, block, layers, os=16, pretrained=False):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        if os == 16:\n",
    "            strides = [1, 2, 2, 1]\n",
    "            dilations = [1, 1, 1, 2]\n",
    "            blocks = [1, 2, 4]\n",
    "        elif os == 8:\n",
    "            strides = [1, 2, 1, 1]\n",
    "            dilations = [1, 1, 2, 2]\n",
    "            blocks = [1, 2, 1]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Modules\n",
    "        self.conv1 = nn.Conv2d(nInputChannels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                bias=False)\n",
    "        self.bn1 = BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=strides[0], dilation=dilations[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=strides[1], dilation=dilations[1])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=strides[2], dilation=dilations[2])\n",
    "        self.layer4 = self._make_MG_unit(block, 512, blocks=blocks, stride=strides[3], dilation=dilations[3])\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "        if pretrained:\n",
    "            self._load_pretrained_model()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, dilation, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_MG_unit(self, block, planes, blocks=[1, 2, 4], stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, dilation=blocks[0]*dilation, downsample=downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, len(blocks)):\n",
    "            layers.append(block(self.inplanes, planes, stride=1, dilation=blocks[i]*dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        low_level_feat = x\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x, low_level_feat\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _load_pretrained_model(self):\n",
    "        pretrain_dict = torch.load('/personal/预训练模型/resnet101.pth')\n",
    "        model_dict = {}\n",
    "        state_dict = self.state_dict()\n",
    "        for k, v in pretrain_dict.items():\n",
    "            if k in state_dict and v.shape == state_dict[k].shape:\n",
    "                model_dict[k] = v\n",
    "        state_dict.update(model_dict)\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "def ResNet101(nInputChannels=3, os=16, pretrained=False):\n",
    "    model = ResNet(nInputChannels, Bottleneck, [3, 4, 23, 3], os, pretrained=pretrained)\n",
    "    return model\n",
    "\n",
    "\n",
    "class ASPP_module(nn.Module):\n",
    "    def __init__(self, inplanes, planes, dilation):\n",
    "        super(ASPP_module, self).__init__()\n",
    "        if dilation == 1:\n",
    "            kernel_size = 1\n",
    "            padding = 0\n",
    "        else:\n",
    "            kernel_size = 3\n",
    "            padding = dilation\n",
    "        self.atrous_convolution = nn.Conv2d(inplanes, planes, kernel_size=kernel_size,\n",
    "                                            stride=1, padding=padding, dilation=dilation, bias=False)\n",
    "        self.bn = BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self._init_weight()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.atrous_convolution(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return self.relu(x)\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class DeepLabv3_plus(nn.Module):\n",
    "    def __init__(self, nInputChannels=3, n_classes=21, os=16, pretrained=False, freeze_bn=False, _print=True):\n",
    "        if _print:\n",
    "            print(\"Constructing DeepLabv3+ model...\")\n",
    "            print(\"Backbone: Resnet-101\")\n",
    "            print(\"Number of classes: {}\".format(n_classes))\n",
    "            print(\"Output stride: {}\".format(os))\n",
    "            print(\"Number of Input Channels: {}\".format(nInputChannels))\n",
    "        super(DeepLabv3_plus, self).__init__()\n",
    "\n",
    "        # Atrous Conv\n",
    "        self.resnet_features = ResNet101(nInputChannels, os, pretrained=pretrained)\n",
    "\n",
    "        # ASPP\n",
    "        if os == 16:\n",
    "            dilations = [1, 6, 12, 18]\n",
    "        elif os == 8:\n",
    "            dilations = [1, 12, 24, 36]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.aspp1 = ASPP_module(2048, 256, dilation=dilations[0])\n",
    "        self.aspp2 = ASPP_module(2048, 256, dilation=dilations[1])\n",
    "        self.aspp3 = ASPP_module(2048, 256, dilation=dilations[2])\n",
    "        self.aspp4 = ASPP_module(2048, 256, dilation=dilations[3])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                             nn.Conv2d(2048, 256, 1, stride=1, bias=False),\n",
    "                                             BatchNorm2d(256),\n",
    "                                             nn.ReLU())\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1280, 256, 1, bias=False)\n",
    "        self.bn1 = BatchNorm2d(256)\n",
    "\n",
    "        # adopt [1x1, 48] for channel reduction.\n",
    "        self.conv2 = nn.Conv2d(256, 48, 1, bias=False)\n",
    "        self.bn2 = BatchNorm2d(48)\n",
    "\n",
    "        self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                                       BatchNorm2d(256),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, n_classes, kernel_size=1, stride=1))\n",
    "        if freeze_bn:\n",
    "            self._freeze_bn()\n",
    "\n",
    "    def one_forward(self, input):\n",
    "        x, low_level_features = self.resnet_features(input)\n",
    "        x1 = self.aspp1(x)\n",
    "        x2 = self.aspp2(x)\n",
    "        x3 = self.aspp3(x)\n",
    "        x4 = self.aspp4(x)\n",
    "        x5 = self.global_avg_pool(x)\n",
    "        x5 = F.upsample(x5, size=x4.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = F.upsample(x, size=(int(math.ceil(input.size()[-2]/4)),\n",
    "                                int(math.ceil(input.size()[-1]/4))), mode='bilinear', align_corners=True)\n",
    "\n",
    "        low_level_features = self.conv2(low_level_features)\n",
    "        low_level_features = self.bn2(low_level_features)\n",
    "        low_level_features = self.relu(low_level_features)\n",
    "\n",
    "\n",
    "        x = torch.cat((x, low_level_features), dim=1)\n",
    "        x = self.last_conv(x)\n",
    "        x = F.interpolate(x, size=input.size()[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        b = input.size(0)\n",
    "        x1 = input[:,:,:512,:512]\n",
    "        x2 = input[:,:,:512,512:]\n",
    "        x3 = input[:,:,512:,:512]\n",
    "        x4 = input[:,:,512:,512:]\n",
    "        x = torch.cat([x1,x2,x3,x4],dim=0)\n",
    "        x = self.one_forward(x)\n",
    "        up = torch.cat([x[:b],x[b:2*b]],dim=3)\n",
    "        down = torch.cat([x[2*b:3*b],x[3*b:]],dim=3)\n",
    "        out = torch.cat([up,down],dim=2)\n",
    "        return out\n",
    "\n",
    "    def _freeze_bn(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085f78d-f9c3-4075-aff9-a306e0e8a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet101 = models.resnet101(pretrained=True)\n",
    "\n",
    "torch.save(resnet101.state_dict(), '/personal/预训练模型/resnet101.pth')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4b71c-ed8d-4f35-8b78-03a4657947a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabv3_plus(nInputChannels=1, n_classes=1, os=16, pretrained=True, freeze_bn=False, _print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f33b1-1fe7-464c-85d8-c29f92f76c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ca91e-0df8-407a-9723-d5e883c2e6d0",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655927c7-3cb5-4e41-b7bb-747ab0567063",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AstroDataset(Dataset):\n",
    "    def __init__(self, map_paths, cat_paths=None):\n",
    "        self.map_paths = map_paths\n",
    "        self.cat_paths = cat_paths\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.map_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image with gaussian smoothing\n",
    "        map_data = gaussian_filter(pyfits.open(self.map_paths[idx])[0].data, sigma=SMOOTHING)\n",
    "        \n",
    "        if self.cat_paths is None:\n",
    "            return torch.FloatTensor(map_data).unsqueeze(0)\n",
    "\n",
    "        # Load catalog\n",
    "        cat = pyfits.open(self.cat_paths[idx])[0].data\n",
    "        target = np.zeros((1024, 1024))\n",
    "\n",
    "        for y, x in cat[:, 1:3]:\n",
    "            target[int(y), int(x)] = 1.0\n",
    "\n",
    "        return torch.FloatTensor(map_data).unsqueeze(0), torch.FloatTensor(target), self.cat_paths[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3971a59-506e-413f-8cbe-db40e629058c",
   "metadata": {},
   "source": [
    "### Model and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ceeda-ec9f-48d5-b999-22b28ce939a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "\n",
    "# Function for applicating model results\n",
    "def detect_objects(model, image_path, confidence_threshold, device=DEVICE):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Load and preprocess image\n",
    "        map_data = gaussian_filter(pyfits.open(image_path)[0].data, sigma=SMOOTHING)\n",
    "        image = torch.FloatTensor(map_data).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        output = model(image)\n",
    "        output = torch.sigmoid(output)\n",
    "        predictions = output.cpu().squeeze().numpy()\n",
    "        \n",
    "        # Convert to coordinates\n",
    "        coordinates = []\n",
    "        for y, x in zip(*np.where(predictions > confidence_threshold)):\n",
    "            confidence = predictions[y, x]\n",
    "            coordinates.append((x, y, confidence))\n",
    "            \n",
    "        return coordinates\n",
    "\n",
    "# Visualizing model predictions\n",
    "def visualize_results(model, image_path, label_path, confidence_threshold, device=DEVICE):\n",
    "    # Get predictions with confidence scores\n",
    "    results = detect_objects(model, image_path, confidence_threshold, device)\n",
    "    results = np.array(results).T if results else np.array([[],[],[]])\n",
    "    \n",
    "    Z = pyfits.open(image_path)[0].data\n",
    "    Z_smooth = gaussian_filter(Z, sigma=SMOOTHING)\n",
    "    \n",
    "    labels = np.transpose(pyfits.open(label_path)[0].data)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(Z_smooth, vmin=-0.1, vmax=0.2, cmap='binary')\n",
    "    plt.scatter(labels[2], labels[1], facecolors='none', edgecolors='red', s=100, label=\"True\")\n",
    "    if len(results[0]) > 0:\n",
    "        # Color the scatter points based on confidence scores\n",
    "        plt.scatter(results[0], results[1], facecolors='none', edgecolors='green', s=100, label=\"Predicted\")\n",
    "    else:\n",
    "        print(\"result length 0\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "Metric function for calculating PR-AUC.\n",
    "This exact function will be used for evaluation\n",
    "'''\n",
    "def calculate_precision_recall_curve(predictions, labels, verbose = True):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"shape of predictions: \", predictions.shape)\n",
    "\n",
    "    # Flatten the predictions and get the indices of the sorted predictions\n",
    "    flat_predictions = predictions.flatten()\n",
    "    sorted_indices = np.argsort(-flat_predictions)  # Sort in descending order\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    true_preds = 0\n",
    "    num_preds = 0\n",
    "    predicted_labels = 0\n",
    "    num_labels = sum(len(l) for l in labels)\n",
    "\n",
    "    labels_within_distance = [[] for _ in range(len(flat_predictions))]\n",
    "\n",
    "    i = 0\n",
    "    for image_idx, image_labels in enumerate(labels):\n",
    "        for y_true, x_true in image_labels:\n",
    "            for y in range(max(0, int(y_true) - 15), min(1024, int(y_true) + 16)):\n",
    "                # Calculate the maximum x distance for the current y\n",
    "                max_x_dist = int((max(0, 15**2 - (y - y_true)**2))**0.5)\n",
    "                # Calculate the range of x-coordinates\n",
    "                for x in range(max(0, int(x_true) - max_x_dist), min(1024, int(x_true) + max_x_dist + 1)):\n",
    "                    coord_idx = image_idx * 1024 * 1024 + y * 1024 + x\n",
    "                    labels_within_distance[coord_idx].append(i)\n",
    "            i += 1\n",
    "    \n",
    "    label_predicted = [False] * num_labels\n",
    "\n",
    "    # Iterate over sorted predictions\n",
    "    for idx in sorted_indices:\n",
    "\n",
    "        num_preds += 1\n",
    "\n",
    "        # Determine the image index and the coordinate within the image\n",
    "        image_idx = idx // (1024 * 1024)\n",
    "        coord_idx = idx % (1024 * 1024)\n",
    "        y, x = divmod(coord_idx, 1024)\n",
    "\n",
    "        if len(labels_within_distance[idx]) > 0:\n",
    "            true_preds += 1\n",
    "            for label in labels_within_distance[idx]:\n",
    "                if label_predicted[label] is False:\n",
    "                    label_predicted[label] = True\n",
    "                    predicted_labels += 1\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        precision = true_preds / num_preds\n",
    "        recall = predicted_labels / num_labels\n",
    "\n",
    "        # Append precision and recall to the lists\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    # Calculate PR-AUC using the trapezoidal rule\n",
    "    pr_auc = np.trapz(precisions, x=recalls)\n",
    "\n",
    "    return precisions, recalls, pr_auc\n",
    "\n",
    "# Evaluate model\n",
    "def get_pr(model, test_loader, device=DEVICE, verbose=True):\n",
    "    model.eval()\n",
    "    outputs_list = []\n",
    "    labels_list = []\n",
    "    for images, _, paths in test_loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            outputs = torch.sigmoid(model(images)).cpu().numpy().squeeze(1)\n",
    "            outputs_list.append(outputs)\n",
    "            cat_data = [np.transpose(pyfits.open(path)[0].data) for path in paths]\n",
    "            labels = [list(zip(cat[1], cat[2])) for cat in cat_data]\n",
    "            labels_list += labels\n",
    "    outputs = np.concat(outputs_list,axis=0)\n",
    "    return calculate_precision_recall_curve(outputs, labels_list, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3668d83-c937-44f2-9c78-80a192e04a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to training data *** do not change *** \n",
    "DATA_DIR = \"/bohr/training-lg02/v1/\"\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "MODEL_SAVE_PATH = \"model.pth\"\n",
    "\n",
    "SMOOTHING = 2.0\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "data_size = len(os.listdir(os.path.join(DATA_DIR, 'map')))\n",
    "dataset = AstroDataset([os.path.join(DATA_DIR, f'map/{i}.fits') for i in range(1, 56+1)], [os.path.join(DATA_DIR, f'cat/{i}.fits') for i in range(1, 56+1)])\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_set = AstroDataset([os.path.join(DATA_DIR, f'map/{i}.fits') for i in range(57, data_size+1)], [os.path.join(DATA_DIR, f'cat/{i}.fits') for i in range(57, data_size+1)])\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb76f68-bd4c-42a1-abef-561cb485ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "weight = torch.tensor([100.0]).cuda()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "model.cuda()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, targets, _ in dataloader:\n",
    "        images = images.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze(1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    train_loss = total_loss/len(dataloader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    _, _, test_auc = get_pr(model, test_loader, verbose=False)\n",
    "    _, _, train_auc = get_pr(model, test_loader, verbose=False)\n",
    "\n",
    "    if (epoch+1)%1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Training Loss: {train_loss:.6f}, Train AUC: {train_auc:.6f}, Test AUC: {test_auc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073798f-8166-489b-9b99-f2fa28c4a175",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70123c08-72dc-4574-a023-16ac14e1ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 30\n",
    "visualize_results(model, dataset.map_paths[i], dataset.cat_paths[i], confidence_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53446661-1613-4dc1-8ccc-6395ca6fb1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PR-AUC\n",
    "precisions, recalls, pr_auc = get_pr(model, test_loader)\n",
    "print(f\"PR-AUC Score: {pr_auc:.4f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curve (AUC = {pr_auc:.4f})')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
